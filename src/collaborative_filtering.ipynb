{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lib.models.content_based_2' from '/Users/mathiasraa/Desktop/ntnu/recommender-systems/src/lib/models/content_based_2.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import lib.models.content_based_2 as content_based\n",
    "import lib.eval as eval\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "import importlib\n",
    "importlib.reload(eval)\n",
    "importlib.reload(content_based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_polars_train = pl.read_csv(\"../data/MINDlarge_train/behaviors.tsv\", separator='\\t', has_header=False)\n",
    "behavior_polars_dev = pl.read_csv(\"../data/MINDlarge_dev/behaviors.tsv\", separator='\\t', has_header=False)\n",
    "behavior_polars_train.columns = ['impression_id', 'user_id', 'time', 'history', 'impressions']\n",
    "behavior_polars_dev.columns = ['impression_id', 'user_id', 'time', 'history', 'impressions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train = pl.read_csv(\"../data/MINDlarge_train/news.tsv\", separator='\\t', has_header=False, quote_char=None)\n",
    "news_dev = pl.read_csv(\"../data/MINDlarge_dev/news.tsv\", separator='\\t', has_header=False, quote_char=None)\n",
    "news_train.columns = ['news_id', 'category', 'subcategory', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities']\n",
    "news_dev.columns = ['news_id', 'category', 'subcategory', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature-ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_behaviors(behaviors_pl):\n",
    "    \"\"\"\n",
    "    Preprocess the behaviors data.\n",
    "    \"\"\"\n",
    "    behaviors_pl = behaviors_pl.with_columns(\n",
    "        pl.col(\"time\").str.to_datetime(\"%m/%d/%Y %I:%M:%S %p\")\n",
    "    )\n",
    "    \n",
    "    # Filter rows with valid impressions\n",
    "    behaviors_pl = behaviors_pl.filter(\n",
    "        ~pl.col(\"impressions\").is_null() & (pl.col(\"impressions\") != \"\")\n",
    "    )\n",
    "    \n",
    "    # Split the impressions string into a list column\n",
    "    with_splits = behaviors_pl.with_columns(\n",
    "        pl.col(\"impressions\").str.split(by=\" \").alias(\"impression_list\")\n",
    "    )\n",
    "    \n",
    "    exploded = with_splits.explode(\"impression_list\")\n",
    "    \n",
    "    # Extract news_id and click from impression string\n",
    "    processed = exploded.with_columns([\n",
    "        pl.col(\"impression_list\").str.split(\"-\").list.get(0).alias(\"news_id\"),\n",
    "        pl.col(\"impression_list\").str.split(\"-\").list.get(1).cast(pl.Int32, strict=False).alias(\"click\"),\n",
    "    ])\n",
    "    \n",
    "    # Select only valid entries and necessary columns\n",
    "    result = processed.filter(\n",
    "        ~pl.col(\"news_id\").is_null() & ~pl.col(\"click\").is_null()\n",
    "    ).select([\n",
    "        \"user_id\", \"impression_id\", \"time\", \"news_id\", \"click\"\n",
    "    ])\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def create_interaction_matrix(interactions_df):\n",
    "    \"\"\"\n",
    "    Create a user-item interaction matrix.\n",
    "    \"\"\"\n",
    "    # Filter to only clicked items (click=1)\n",
    "    clicked_interactions = interactions_df[interactions_df['click'] == 1]\n",
    "    \n",
    "    user_ids = clicked_interactions['user_id'].unique()\n",
    "    news_ids = clicked_interactions['news_id'].unique()\n",
    "    \n",
    "    user_map = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    news_map = {news_id: idx for idx, news_id in enumerate(news_ids)}\n",
    "    \n",
    "    # Create the interaction matrix\n",
    "    rows = clicked_interactions['user_id'].map(user_map).values\n",
    "    cols = clicked_interactions['news_id'].map(news_map).values\n",
    "    values = np.ones(len(rows))\n",
    "    \n",
    "    interaction_matrix = csr_matrix((values, (rows, cols)), \n",
    "                                   shape=(len(user_ids), len(news_ids)))\n",
    "    \n",
    "    return interaction_matrix, user_map, news_map\n",
    "\n",
    "def compute_item_similarity(interaction_matrix):\n",
    "    \"\"\"\n",
    "    Compute item-item similarity using cosine similarity.\n",
    "    \"\"\"\n",
    "    # Transpose to get item features (users who interacted with each item)\n",
    "    item_features = interaction_matrix.T\n",
    "\n",
    "    return cosine_similarity(item_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hybrid_similarity_matrix(interaction_matrix, news_df, news_map):\n",
    "    \"\"\"\n",
    "    Create a hybrid similarity matrix incorporating both collaborative signals\n",
    "    and content-based similarity.\n",
    "    \"\"\"\n",
    "    # Create content features from news categories and subcategories\n",
    "    news_ids = list(news_map.keys())\n",
    "    n_news = len(news_ids)\n",
    "    \n",
    "    # Create one-hot encoding for categories and subcategories\n",
    "    categories = news_df['category'].unique().tolist()\n",
    "    subcategories = news_df['subcategory'].unique().tolist()\n",
    "    \n",
    "    cat_map = {cat: i for i, cat in enumerate(categories)}\n",
    "    subcat_map = {subcat: i for i, subcat in enumerate(subcategories)}\n",
    "    \n",
    "    # Initialize feature matrix\n",
    "    # Features: [category_oh, subcategory_oh]\n",
    "    feat_matrix = np.zeros((n_news, len(categories) + len(subcategories)))\n",
    "    \n",
    "    for news_id, idx in news_map.items():\n",
    "        news_info = news_df[news_df['news_id'] == news_id]\n",
    "        if len(news_info) > 0:\n",
    "            # Add category one-hot\n",
    "            cat = news_info.iloc[0]['category']\n",
    "            if cat in cat_map:\n",
    "                feat_matrix[idx, cat_map[cat]] = 1.0\n",
    "                \n",
    "            # Add subcategory one-hot\n",
    "            subcat = news_info.iloc[0]['subcategory']\n",
    "            if subcat in subcat_map:\n",
    "                feat_matrix[idx, len(categories) + subcat_map[subcat]] = 1.0\n",
    "    \n",
    "    # Compute content-based similarity\n",
    "    content_similarity = cosine_similarity(feat_matrix)\n",
    "    # Compute collaborative similarity\n",
    "    collaborative_similarity = cosine_similarity(interaction_matrix.T)\n",
    "    \n",
    "    # Weighted hybrid similarity\n",
    "    hybrid_similarity = 0.7 * collaborative_similarity + 0.3 * content_similarity\n",
    "    \n",
    "    return hybrid_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_evaluate_hybrid(test_interactions, interaction_matrix, similarity_matrix, \n",
    "                       user_map, news_map, sampled_users):\n",
    "    \"\"\"\n",
    "    Sample users and evaluate the model\n",
    "    \"\"\"\n",
    "    test_sample = test_interactions.filter(pl.col(\"user_id\").is_in(sampled_users))\n",
    "    \n",
    "    # Create a map to look up user_id by impression_id \n",
    "    impression_to_user = {row[\"impression_id\"]: row[\"user_id\"] \n",
    "                          for row in test_sample.select([\"impression_id\", \"user_id\"]).unique().iter_rows(named=True)}\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions = []\n",
    "    for row in test_sample.select([\"impression_id\", \"news_id\"]).unique().iter_rows(named=True):\n",
    "        impression_id = row[\"impression_id\"]\n",
    "        news_id = row[\"news_id\"]\n",
    "        \n",
    "        # Skip if impression or news not in maps\n",
    "        if impression_id not in impression_to_user or news_id not in news_map:\n",
    "            continue\n",
    "        \n",
    "        user_id = impression_to_user[impression_id]\n",
    "        if user_id not in user_map:\n",
    "            continue\n",
    "            \n",
    "        user_idx = user_map[user_id]\n",
    "        news_idx = news_map[news_id]\n",
    "        \n",
    "        # Get user interactions\n",
    "        user_interactions = interaction_matrix[user_idx].toarray().flatten()\n",
    "        interacted_indices = np.where(user_interactions > 0)[0]\n",
    "        \n",
    "        if len(interacted_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Calculate score by combining collaborative and recency factors\n",
    "        collab_score = 0.0\n",
    "        for idx in interacted_indices:\n",
    "            collab_score += similarity_matrix[idx, news_idx] * user_interactions[idx]\n",
    "        \n",
    "        \n",
    "        # Add prediction\n",
    "        predictions.append({\n",
    "            \"impression_id\": impression_id,\n",
    "            \"news_id\": news_id,\n",
    "            \"score\": float(collab_score)\n",
    "        })\n",
    "\n",
    "    return pl.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting some results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_evaluate(test_interactions, interaction_matrix, similarity_matrix, \n",
    "                       user_map, news_map, sampled_users):\n",
    "    # Filter test data to only include sampled users\n",
    "    test_sample = test_interactions.filter(pl.col(\"user_id\").is_in(sampled_users))\n",
    "    print(f\"Sample contains {len(test_sample)} interactions\")\n",
    "\n",
    "\n",
    "    # Extract unique user-news pairs to score\n",
    "    unique_pairs = test_sample.select([\"impression_id\", \"user_id\", \"news_id\"]).unique()\n",
    "    print(f\"Unique pairs to score: {len(unique_pairs)}\")\n",
    "\n",
    "    # Convert to pandas for easier processing\n",
    "    pairs_pd = unique_pairs.to_pandas()\n",
    "\n",
    "    # Initialize predictions list\n",
    "    predictions = []\n",
    "\n",
    "    batch_size = 1000\n",
    "    num_batches = (len(pairs_pd) + batch_size - 1) // batch_size\n",
    "\n",
    "    print(\"Generating predictions...\")\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(pairs_pd))\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Processing batch {batch_idx+1}/{num_batches}\")\n",
    "        \n",
    "        batch = pairs_pd.iloc[start_idx:end_idx]\n",
    "        \n",
    "        for _, row in batch.iterrows():\n",
    "            user_id = row['user_id']\n",
    "            news_id = row['news_id']\n",
    "            impression_id = row['impression_id']\n",
    "            \n",
    "            # Skip if news not in training\n",
    "            if news_id not in news_map:\n",
    "                continue\n",
    "                \n",
    "            # Get user profile\n",
    "            user_idx = user_map[user_id]\n",
    "            news_idx = news_map[news_id]\n",
    "            \n",
    "            # Get user interactions\n",
    "            user_interactions = interaction_matrix[user_idx].toarray().flatten()\n",
    "            interacted_indices = np.where(user_interactions > 0)[0]\n",
    "            \n",
    "            if len(interacted_indices) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Calculate score\n",
    "            score = 0.0\n",
    "            for idx in interacted_indices:\n",
    "                if idx < similarity_matrix.shape[0] and news_idx < similarity_matrix.shape[1]:\n",
    "                    score += similarity_matrix[idx, news_idx] * user_interactions[idx]\n",
    "            \n",
    "            # Add prediction\n",
    "            predictions.append({\n",
    "                \"impression_id\": impression_id,\n",
    "                \"news_id\": news_id,\n",
    "                \"score\": float(score)\n",
    "            })\n",
    "    return pl.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_train.to_pandas()\n",
    "behaviors_df = behavior_polars_train.to_pandas()\n",
    "\n",
    "train_interactions = preprocess_behaviors(behavior_polars_train)\n",
    "test_interactions = preprocess_behaviors(behavior_polars_dev)\n",
    "\n",
    "interaction_matrix, user_map, news_map = create_interaction_matrix(train_interactions.to_pandas())\n",
    "item_similarity = compute_item_similarity(interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampled_users(test_interactions, user_map, sample_size=3000):\n",
    "    \"\"\"\n",
    "    Sample users who exist in both test and training data.\n",
    "    \"\"\"\n",
    "    test_users = set(test_interactions[\"user_id\"].unique().to_list())\n",
    "    train_users = set(user_map.keys())\n",
    "    valid_users = list(test_users.intersection(train_users))\n",
    "    \n",
    "    sample_size = min(sample_size, len(valid_users))\n",
    "    sampled_users = random.sample(valid_users, sample_size)\n",
    "    \n",
    "    return sampled_users\n",
    "\n",
    "sampled_users = get_sampled_users(test_interactions, user_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample contains 166836 interactions\n",
      "Unique pairs to score: 166836\n",
      "Generating predictions...\n",
      "Processing batch 1/167\n",
      "Processing batch 11/167\n",
      "Processing batch 21/167\n",
      "Processing batch 31/167\n",
      "Processing batch 41/167\n",
      "Processing batch 51/167\n",
      "Processing batch 61/167\n",
      "Processing batch 71/167\n",
      "Processing batch 81/167\n",
      "Processing batch 91/167\n",
      "Processing batch 101/167\n",
      "Processing batch 111/167\n",
      "Processing batch 121/167\n",
      "Processing batch 131/167\n",
      "Processing batch 141/167\n",
      "Processing batch 151/167\n",
      "Processing batch 161/167\n"
     ]
    }
   ],
   "source": [
    "predictions_df = sample_and_evaluate(\n",
    "    test_interactions,\n",
    "    interaction_matrix,\n",
    "    item_similarity,\n",
    "    user_map,\n",
    "    news_map,\n",
    "    sampled_users\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>mrr</th>\n",
       "      <th>ndcg@5</th>\n",
       "      <th>ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.502965</td>\n",
       "      <td>0.239347</td>\n",
       "      <td>0.245703</td>\n",
       "      <td>0.297866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        auc       mrr    ndcg@5   ndcg@10\n",
       "0  0.502965  0.239347  0.245703  0.297866"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results = eval.evaluate_mind_predictions(\n",
    "    predictions_df,\n",
    "    behaviors_df=behavior_polars_dev.filter(pl.col(\"user_id\").is_in(sampled_users)),  # Only use the sampled test data\n",
    "    metrics=[\"auc\", \"mrr\", \"ndcg@5\", \"ndcg@10\"]\n",
    ")\n",
    "\n",
    "pd.DataFrame(eval_results, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from the revised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_similarity = create_hybrid_similarity_matrix(interaction_matrix, news_df, news_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_predictions = sample_and_evaluate_hybrid(\n",
    "    test_interactions, \n",
    "    interaction_matrix, \n",
    "    hybrid_similarity,\n",
    "    user_map, \n",
    "    news_map, \n",
    "    sampled_users\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>mrr</th>\n",
       "      <th>ndcg@5</th>\n",
       "      <th>ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.582429</td>\n",
       "      <td>0.289803</td>\n",
       "      <td>0.302928</td>\n",
       "      <td>0.349088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        auc       mrr    ndcg@5   ndcg@10\n",
       "0  0.582429  0.289803  0.302928  0.349088"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results = eval.evaluate_mind_predictions(\n",
    "    hybrid_predictions,\n",
    "    behaviors_df=behavior_polars_dev.filter(pl.col(\"user_id\").is_in(sampled_users)), \n",
    "    metrics=[\"auc\", \"mrr\", \"ndcg@5\", \"ndcg@10\"]\n",
    ")\n",
    "\n",
    "pd.DataFrame(eval_results, index=[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
